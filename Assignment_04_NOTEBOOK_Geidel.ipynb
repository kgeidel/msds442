{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# MSDS 442: AI Agent Design and Development\n",
    "# Spring '25\n",
    "# Dr. Bader\n",
    "#\n",
    "# Assignment 4 - Northwestern Memorial â€“ Healthcare Agent\n",
    "# \n",
    "# Kevin Geidel\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "# OBJECTIVE:\n",
    "#   The following will construct multiple AI agents using the LangChain & LangGraph frameworks. \n",
    "#   The agents will represent different departments of Northwestern Memorial Hospital.\n",
    "#   They will coordinate, synchronize, and act to answer patients'/visitors' questions.\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Python native imports\n",
    "import os, textwrap, json\n",
    "\n",
    "# 3rd party package imports\n",
    "from IPython.display import display, Image\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Assign experiment-wide variables\n",
    "model_name = 'gpt-4o-mini'\n",
    "data_dir = os.path.join('reports', 'Assignment_4')\n",
    "knowledge_base_dir = os.path.join('knowledge_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0faa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Define the structure of agent state for the LangGraph\n",
    "class InquiryState(TypedDict):\n",
    "    inquiry: str\n",
    "    referring_node: str\n",
    "    next_node: str\n",
    "    response: str\n",
    "    messages: Annotated[Sequence[BaseMessage], \"List of messages in the conversation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c867f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the AI client\n",
    "llm = ChatOpenAI(model=model_name, temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab17882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utils needed by the agents\n",
    "\n",
    "def load_knowledge_base(filename):\n",
    "    # Extract inquires and responses from the JSON format knowledge base\n",
    "    full_path = os.path.join(knowledge_base_dir, filename)\n",
    "    with open(full_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return str(data)\n",
    "\n",
    "def get_query_from_inquiry(inquiry, messages=None):\n",
    "    prompt_str = f\"\"\"Provide an answer for following user's inquiry: '{inquiry}' using the knowledge_base.\"\"\"\n",
    "    if messages:\n",
    "        history = \"\\n\".join([f'{msg.type}: {msg.content}' for msg in messages][:5])\n",
    "        prompt_str += f\"\"\"\\n\\nConversation history for context:\\n\\n{history}\"\"\"\n",
    "    return prompt_str\n",
    "\n",
    "def get_human_message_for_agent(state):\n",
    "    # Return the \"HumanMessage\" that forwards the user's inquiry (or last agent's inquiry) to the next agent\n",
    "    return HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": get_query_from_inquiry(state['inquiry'], state.get(\"messages\", []))},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "def get_system_message_for_agent(knowledge_base_filename, department=None):\n",
    "    return SystemMessage(\n",
    "        content=f\"You are a helpful assistant for the {department} department at Northwestern Memorial Hospital. Answer the user's inquiry based solely on the answers you have in this knowledge_base: {load_knowledge_base(knowledge_base_filename)}\\n\\nUse the conversation history to provide contextually relevant responses. If the user says 'quit' or indicates the conversation is complete, respond appropriately and signal the end. Otherwise, continue the conversation within the {department} department.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccadeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_router(state):\n",
    "    inquiry = state['inquiry'].lower()\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # Check for end of conversation\n",
    "    if inquiry in ['q', 'quit']:\n",
    "        return {\n",
    "            \"inquiry\": state[\"inquiry\"],\n",
    "            \"referring_node\": \"Operator\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": \"Goodbye! Thank you for contacting Northwestern Memorial!\",\n",
    "            \"messages\": messages + [HumanMessage(content=inquiry), SystemMessage(content=\"Conversation ended by user.\")]            \n",
    "        }\n",
    "    \n",
    "    # Check for an ongoing conversation\n",
    "    if state.get('referring_node') != \"Operator\" and state.get('next_node'):\n",
    "        history = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in messages][:5])\n",
    "        query = f\"\"\"Given the conversation history and the new inquiry: '{inquiry}', determine if this is a follow-up question related to the previous department ({state['referring_node']}) or a new topic. Return 'continue' if it's a follow-up, or classify the intent for a new topic.\n",
    "        Possible intent values: Greeting, GeneralInquiry, ER, Radiology, PrimaryCare, Cardiology, Pediatrics, BillingInsurance\n",
    "        \n",
    "        Conversation history:\n",
    "        {history}\n",
    "        \"\"\"\n",
    "        messages_for_intent = [\n",
    "            SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of a user's query or detecting follow-ups.\"),\n",
    "            HumanMessage(content=[{'type': 'text', 'text': query}])\n",
    "        ]\n",
    "        response = llm.invoke(messages_for_intent)\n",
    "        intent = response.content.strip()\n",
    "        if intent == 'continue':\n",
    "            return {\n",
    "                \"inquiry\": state[\"inquiry\"],\n",
    "                \"referring_node\": \"Operator\",\n",
    "                \"next_node\": state['referring_node'],\n",
    "                \"response\": f\"Continuing with the {state['referring_node']} department.\",\n",
    "                \"messages\": messages + [HumanMessage(content=inquiry)]            \n",
    "            }            \n",
    "\n",
    "    # This is a new conversation. Have the operator decide how to route.\n",
    "    query = f\"\"\"Classify the user's intents based on the following input: '{state['inquiry']}'. \n",
    "            List of possible intent values: Greeting, GeneralInquiry, ER, Radiology, PrimaryCare, Cardiology, Pediatrics, BillingInsurance\n",
    "            Return only the intent value of the inquiry identified with no extra text or characters\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of user's inquiry\"),\n",
    "        HumanMessage(content=[{\"type\": \"text\", \"text\": query}]),\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    intent = response.content.strip()\n",
    "            \n",
    "    response_lower = intent.lower()\n",
    "    \n",
    "    if \"greeting\" in response_lower:\n",
    "        response = \"Hello there, This is Northwestern Memorial Hospital, How can I assist you today?\"\n",
    "        next_node = END\n",
    "    elif \"generalinquiry\" in response_lower:\n",
    "        response = \"For general informtion about nearby parking, hotels and restaurants, please visit https://www.nm.org/ and navigate to Patients & Visitors link \"\n",
    "        next_node = END\n",
    "    else:\n",
    "        response = f\"Let me forward your query to our {intent} agent.\"\n",
    "        next_node = intent\n",
    "\n",
    "    return {\n",
    "        \"inquiry\": state[\"inquiry\"],\n",
    "        \"referring_node\": \"Operator\",\n",
    "        \"next_node\": next_node,\n",
    "        \"response\": response,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ce55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def department_specific_agent(state, department_node_name, knowledge_base_filename):\n",
    "    # Handle inquires related to the passed department\n",
    "    inquiry = state['inquiry'].lower()\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Check for end of conversation\n",
    "    if inquiry in ['q', 'quit']:\n",
    "        return {\n",
    "            \"inquiry\": state[\"inquiry\"],\n",
    "            \"referring_node\": department_node_name,\n",
    "            \"next_node\": END,\n",
    "            \"response\": f\"Goodbye! Thank you for contacting {department_node_name} at Northwestern Memorial!\",\n",
    "            \"messages\": messages + [HumanMessage(content=inquiry), SystemMessage(content=\"Conversation ended by user.\")]            \n",
    "        }\n",
    "    \n",
    "    if state['referring_node'] == 'Operator':\n",
    "        # This is first pass at the department agent, include the system message\n",
    "        messages += [get_system_message_for_agent(knowledge_base_filename)]+[get_human_message_for_agent(state)]\n",
    "    else:\n",
    "        # This is an ongoing conversation. Just append new inquiry\n",
    "        messages += [get_human_message_for_agent(state)]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    formatted_response = f\"{department_node_name}:: \" + response.content.strip()\n",
    "\n",
    "    # Check if conversation is over (next_node=END) or not (next_node=same department)\n",
    "    completion_check = llm.invoke([\n",
    "        SystemMessage(content=f\"Determine if the user's inquiry is fully resolved based on the response: '{response.content}'.\\n\\nReturn 'complete' if resolved, 'continue' if further interaction is needed.\"),\n",
    "        HumanMessage(content=[{'type': 'text', 'text': f'Response: {response.content}'}])\n",
    "    ])\n",
    "    next_node = END if completion_check.content.strip() == 'continue' else department_node_name\n",
    "\n",
    "    return {\n",
    "        \"input\": state[\"inquiry\"],\n",
    "        \"referring_node\": department_node_name,\n",
    "        \"next_node\": next_node, \n",
    "        \"response\": formatted_response,\n",
    "        \"messages\": messages + [SystemMessage(content=formatted_response)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7885ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_agent(state):\n",
    "    # Handle inquires related to the ER department\n",
    "    return department_specific_agent(state, 'ER', 'emergency.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e45961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiology_agent(state):\n",
    "    # Handle inquires related to the Radiology department\n",
    "    return department_specific_agent(state, 'Radiology', 'radiology.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_care_agent(state):\n",
    "    # Handle inquires related to the PrimaryCare department\n",
    "    return department_specific_agent(state, 'PrimaryCare', 'primary_care.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardiology_agent(state):\n",
    "    # Handle inquires related to the Cardiology department\n",
    "    return department_specific_agent(state, 'Cardiology', 'cardiology.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pediatrics_agent(state):\n",
    "    # Handle inquires related to the Pediatrics department\n",
    "    return department_specific_agent(state, 'Pediatrics', 'pediatrics.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def billing_agent(state):\n",
    "    # Handle inquires related to the BillingInsurance department\n",
    "    return department_specific_agent(state, 'BillingInsurance', 'billing.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79223c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(InquiryState)\n",
    "\n",
    "builder.add_node(\"Operator\", operator_router)\n",
    "builder.add_node(\"ER\", er_agent)\n",
    "builder.add_node(\"Radiology\", radiology_agent)\n",
    "builder.add_node(\"PrimaryCare\", primary_care_agent)\n",
    "builder.add_node(\"Cardiology\", cardiology_agent)\n",
    "builder.add_node(\"Pediatrics\", pediatrics_agent)\n",
    "builder.add_node(\"BillingInsurance\", billing_agent)\n",
    "\n",
    "builder.set_entry_point(\"Operator\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"Operator\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {\n",
    "        \"ER\": \"ER\",\n",
    "        \"PrimaryCare\": \"PrimaryCare\",\n",
    "        \"Pediatrics\": \"Pediatrics\",\n",
    "        \"Radiology\": \"Radiology\",\n",
    "        \"Cardiology\": \"Cardiology\",\n",
    "        \"BillingInsurance\": \"BillingInsurance\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "for node in [\"ER\", \"Radiology\", \"PrimaryCare\", \"Cardiology\", \"Pediatrics\", \"BillingInsurance\"]:\n",
    "    builder.add_edge(node, END)\n",
    "\n",
    "    \n",
    "graph = builder.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58352e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd13a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    print(f\"\\nUser:\\n\\n {user_input}\")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    result = graph.invoke({\"inquiry\": user_input}, config=config)\n",
    "    response = result.get(\"response\", \"No Response Returned\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ced16b0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "How can I tell if my child has RSV (Respiratory Syncytial Virus)?\n",
    "\n",
    "Can I visit my friend in the ER, and are there any restrictions?\n",
    "\n",
    "How should I prepare for a CT scan, and are there any dietary restrictions?\n",
    "\n",
    "I want to check if my recent test result has been reviewed by my primary care physician yet?\n",
    "\n",
    "Do you have any available appointments with a cardiologist next week?\n",
    "\n",
    "Can you help me understand my recent medical bill and whether my insurance covered the costs?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
