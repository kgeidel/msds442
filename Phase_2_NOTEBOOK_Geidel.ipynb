{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd9a7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# MSDS 442: AI Agent Design and Development\n",
    "# Spring '25\n",
    "# Dr. Bader\n",
    "#\n",
    "# Final Project: AI Agent Automation for Pelotonâ€™s Fitness Ecosystem\n",
    "# Phase 2 - Prototype\n",
    "# \n",
    "# Kevin Geidel\n",
    "#\n",
    "#######################################################################\n",
    "\n",
    "# OBJECTIVE:\n",
    "#   Construct a high-fidelity prototype of the Peloton Automation. \n",
    "#   Implement the planned architecture using Phase 1 Artifacts.\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Python native imports\n",
    "import os, inspect, textwrap, time\n",
    "from typing import Annotated, Sequence\n",
    "\n",
    "# LangChain/LangGraph imports\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 3rd party package imports\n",
    "from IPython.display import display, Image\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c867f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PelotonAgent:\n",
    "    ''' Namespace for methods and metaclasses that facilliate Peloton's Agent-based automation. '''\n",
    "\n",
    "    class InquiryState(TypedDict):\n",
    "        inquiry: str\n",
    "        response: str\n",
    "        referring_node: str\n",
    "        next_node: str\n",
    "        messages: Annotated[Sequence[BaseMessage], \"List of messages in the conversation\"]\n",
    "\n",
    "    def __init__(self):\n",
    "        # Assign agent-wide variables\n",
    "        self.model_name = 'gpt-4o-mini'\n",
    "        self.data_dir = os.path.join('src')\n",
    "        self.agent_data_path = os.path.join(self.data_dir, 'ai_agent_test_data.json')        \n",
    "        \n",
    "        # Establish the AI client\n",
    "        self.llm = ChatOpenAI(model=self.model_name, temperature=0)\n",
    "\n",
    "        # Load test data into memory in form of langchain docs\n",
    "        self.load_documents()\n",
    "\n",
    "        # Construct the agent graph\n",
    "        self.build_graph()\n",
    "\n",
    "    def load_documents(self):\n",
    "        loader = JSONLoader(\n",
    "            file_path=self.agent_data_path, \n",
    "            jq_schema='.',\n",
    "            text_content=False,\n",
    "        )\n",
    "        self.data= loader.load()\n",
    "    \n",
    "    def build_graph(self):\n",
    "        builder = StateGraph(self.InquiryState)\n",
    "        # nodes\n",
    "        builder.add_node('Router', self.router_agent)\n",
    "        builder.add_node('Marketing', self.marketing_agent)\n",
    "        builder.add_node('DataScience', self.data_science_agent)\n",
    "        builder.add_node('Membership', self.membership_agent)\n",
    "        builder.add_node('Orders', self.orders_agent)\n",
    "        builder.add_node('Recommendations', self.recommendation_agent)\n",
    "        # edges/workflow\n",
    "        builder.add_edge(START, 'Router')\n",
    "        builder.add_conditional_edges(\n",
    "            'Router',\n",
    "            lambda x: x['next_node'],\n",
    "        )\n",
    "        for node in ['Marketing', 'DataScience', 'Membership', 'Orders', 'Recommendations']:\n",
    "            builder.add_edge(node, END)\n",
    "        \n",
    "        self.graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "    def draw_graph(self):\n",
    "        display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "    \n",
    "    # base methods for agents\n",
    "    def termination_check(self, state):\n",
    "        ''' Check for user end session '''\n",
    "        inquiry = state.get('inquiry', '')\n",
    "        if inquiry.lower() in ['q', 'quit', 'goodbye', 'bye']:\n",
    "            return {\n",
    "                \"inquiry\": inquiry,\n",
    "                \"referring_node\": state.get('next_node', 'Router'),\n",
    "                \"next_node\": END,\n",
    "                \"response\": \"Goodbye! Thank you for contacting the Peloton automated AI agent!\",\n",
    "                \"messages\": state.get('messages', []) + [HumanMessage(content=inquiry), SystemMessage(content=\"Conversation ended by user.\")]            \n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def route_ongoing_chat(self, state, max_history=5):\n",
    "        inquiry = state.get('inquiry', '')\n",
    "        messages = state.get(\"messages\", [])\n",
    "        if state.get('referring_node') != \"Router\" and state.get('next_node'):\n",
    "            history = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in state.get(\"messages\", [])][:max_history])\n",
    "            query = f\"\"\"Given the conversation history and the new inquiry: '{inquiry}', determine if this is a follow-up question related to the previous department ({state['referring_node']}) or a new topic. Return 'continue' if it's a follow-up, or classify the intent for a new topic.\n",
    "            Possible intent values: Greeting, GeneralInquiry, Marketing, DataScience, Membership, Orders, Recommendations\n",
    "            \n",
    "            Conversation history:\n",
    "            {history}\n",
    "            \"\"\"\n",
    "            messages_for_intent = [\n",
    "                SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of a user's query or detecting follow-ups.\"),\n",
    "                HumanMessage(content=[{'type': 'text', 'text': query}])\n",
    "            ]\n",
    "            response = self.llm.invoke(messages_for_intent)\n",
    "            intent = response.content.strip()\n",
    "            if intent == 'continue':\n",
    "                return {\n",
    "                    \"inquiry\": state[\"inquiry\"],\n",
    "                    \"referring_node\": \"Router\",\n",
    "                    \"next_node\": state['referring_node'],\n",
    "                    \"response\": f\"Routing to the {state['referring_node']} department.\",\n",
    "                    \"messages\": messages + [HumanMessage(content=inquiry)]            \n",
    "                }\n",
    "        return {}    \n",
    "\n",
    "    def unimplemented_agent(self, state):\n",
    "        calling_agent = inspect.currentframe().f_back.f_code.co_name\n",
    "        return {\n",
    "            'inquiry': state['inquiry'],\n",
    "            'response': f'{calling_agent} is not yet implemented.',\n",
    "            'referring_node': state.get('referring_node', None),\n",
    "            'next_node': END,\n",
    "            'messages': state.get('messages', []) + [SystemMessage(content=f'Routed to unimplented agent, {calling_agent}.')]\n",
    "        }\n",
    "\n",
    "    # define agents methods\n",
    "    def router_agent(self, state):\n",
    "        inquiry = state.get('inquiry', '')\n",
    "        messages = state.get('messages', [])\n",
    "\n",
    "        # check for termination by user\n",
    "        terminate = self.termination_check(state)\n",
    "        if terminate:\n",
    "            return terminate\n",
    "        \n",
    "        # check for ongoing conversation\n",
    "        ongoing = self.route_ongoing_chat(state)\n",
    "        if ongoing:\n",
    "            return ongoing\n",
    "    \n",
    "        # Classify intent for this new session and route\n",
    "        query = f\"\"\"Classify the user's intents based on the following input: '{inquiry}'. \n",
    "                List of possible intent values: Greeting, GeneralInquiry, Marketing, DataScience, Membership, Orders, Recommendations\n",
    "                Return only the intent value of the inquiry identified with no extra text or characters\"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of user's inquiry\"),\n",
    "            HumanMessage(content=[{\"type\": \"text\", \"text\": query}]),\n",
    "        ]\n",
    "        response = self.llm.invoke(messages)\n",
    "        intent = response.content.strip()\n",
    "        response_lower = intent.lower()\n",
    "        \n",
    "        if \"greeting\" in response_lower:\n",
    "            response = \"Hello there, this is the Peloton automated AI agent. How can I assist you today?\"\n",
    "            next_node = END\n",
    "        elif \"generalinquiry\" in response_lower:\n",
    "            response = \"For general informtion about Peloton's ecosystem of classes and products visit https://www.onepeloton.com/. Thank you!\"\n",
    "            next_node = END\n",
    "        else:\n",
    "            response = f\"Let me forward your query to our {intent} agent.\"\n",
    "            next_node = intent\n",
    "\n",
    "        return {\n",
    "            \"inquiry\": state[\"inquiry\"],\n",
    "            \"referring_node\": \"Router\",\n",
    "            \"next_node\": next_node,\n",
    "            \"response\": response,\n",
    "        }       \n",
    "\n",
    "    def marketing_agent(self, state):\n",
    "        return self.unimplemented_agent(state)\n",
    "    \n",
    "    def data_science_agent(self, state):\n",
    "        return self.unimplemented_agent(state)\n",
    "    \n",
    "    def membership_agent(self, state):\n",
    "        return self.unimplemented_agent(state)\n",
    "    \n",
    "    def orders_agent(self, state):\n",
    "        return self.unimplemented_agent(state)\n",
    "    \n",
    "    def recommendation_agent(self, state):\n",
    "        return self.unimplemented_agent(state)\n",
    "    \n",
    "    def invoke(self, thread_id=\"1\"):\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            time.sleep(0.5)\n",
    "            print(f\"User:\\n  {user_input}\")\n",
    "            time.sleep(0.5)\n",
    "            if user_input.lower() in {\"q\", \"quit\"}:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            result = self.graph.invoke({\"inquiry\": user_input}, config=config)\n",
    "            time.sleep(0.5)\n",
    "            response = result.get(\"response\", \"No Response Returned\")\n",
    "            print('Agent:\\n ', textwrap.fill(response, 80))       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66997251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "  Hello?\n",
      "Agent:\n",
      "  Hello there, this is the Peloton automated AI agent. How can I assist you today?\n",
      "User:\n",
      "  Marketing\n",
      "Agent:\n",
      "  marketing_agent is not yet implemented.\n",
      "User:\n",
      "  Bye!\n",
      "Agent:\n",
      "  Hello there, this is the Peloton automated AI agent. How can I assist you today?\n",
      "User:\n",
      "  q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "bot = PelotonAgent()\n",
    "# bot.draw_graph()\n",
    "bot.invoke()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90764abc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "For the Final Project Phase_2, please see below the recommended guidelines when you start working on this phase:\n",
    "\n",
    "- Based on the work that you have completed for Phase_1, pick any 3 Agents for the design and development in Phase_2\n",
    "\n",
    "- Consider reusing/modifying Assignment_3 IPYNB script for the Final Project_Phase_2; you are free to create your own IPYNB script\n",
    "\n",
    "- Provide the implementation of one user-story from the list of user stories you identified in Phase_1 for every agent of 3 agents you select to work on in Phase_2; these same 3 agents you will provide their complete implementation in Phase_3 for their user-stories you listed in Phase_1\n",
    "\n",
    "- Your submission for Final Project Phase_2 must demonstrate a working prototype even though it is not a complete implementation for all user-stories; you will provide the complete implementation in Phase_3 for all user-stories  of the 3 agents you select in Phase_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
